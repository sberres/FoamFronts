{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of foam front propagation on a primal mesh\n",
    "\n",
    "The goal of this document is to document step-by step the development of the implementation for simulation of foam front propagation on a primal mesh.\n",
    "\n",
    "-----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solving the coupled equations \n",
    "\\begin{align*}\n",
    "    T_t + \\| \\nabla T \\| = v \\\\\n",
    "    \\frac{\\nabla T}{\\| \\nabla T \\|} = \\nabla S\n",
    "\\end{align*}\n",
    "on a primary mesh\n",
    "there are various strategies. We can opt to solve the transient equation for \n",
    "$t \\rightarrow \\infty$, for speed with large time steps and for stability by an implicit method. This emulates the iteration.\n",
    "\n",
    "The alternative is to solve the stationary equations,\n",
    "\n",
    "We have the coupled system of equations:\n",
    "\\begin{align*}\n",
    "   H_T(T, S) = \\| \\nabla T \\| - v = 0 \\\\\n",
    "   H_S(T, S) = \\frac{\\nabla T}{\\| \\nabla T \\|} - \\nabla S = 0\n",
    "\\end{align*}\n",
    "which we write in compact form as\n",
    "\\begin{align*}\n",
    "    U = (S,T) ,\n",
    "    \\qquad\n",
    "    H(U) =\n",
    "    \\begin{pmatrix}\n",
    "       H_1(T, S) \\\\\n",
    "       H_2(T, S) \n",
    "    \\end{pmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "One mayor design issue is the choice of the numerical Hamiltonian,\n",
    "and there whether the weighting of the gradients is done before or after the evaluation of the Hamiltonian.\n",
    "\n",
    "Given the gradients $G_1, G_2, G_3$ \n",
    "and ponderations $w_1, w_2, w_3$\n",
    "to triangles attached to a node, con can\n",
    "first average and then calculate the Hamiltonian of that average, \n",
    "or first calculate the Hamiltonian and then average the evaluated functions.\n",
    "\n",
    "\\begin{align*}\n",
    "    H(G_1, G_2, G_3) = \\begin{cases}\n",
    "        \\frac{w_1 H(G_1) + w_2 H(G_2) + w_3 H(G_3)}{w_1 + w_2 + w_3} \\\\\n",
    "        H \\Biggl( \\frac{w_1 G_1 + w_2 G_2 + w_3 G_3}{w_1 + w_2 + w_3} \\Biggr)\n",
    "        \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Now, one choice for the weigts is to set them equal to the corresponding angle.\n",
    "\n",
    "Another mayor design choice is the type of grid, whether it is rectangular, triangular or with more general poligons, and wether the discrete values are considered on a primary or on a dual grid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a discretizaion on a primary grid, i.e. the solution values are associated to the vertices. \n",
    "For each vertex there are two discrete variables.\n",
    "\n",
    "For a well determined system of equations we need two equations associated to these vertices.\n",
    "\n",
    "So, when assembling the system of equations we run over all vertices. In order to handle the geometry we need to acces the positions of each vertex.\n",
    "\n",
    "The following code iterates over the vertices, giving the index and position of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [  0 ,  0 ]\n",
      "1 : [  0 ,  10 ]\n",
      "2 : [  10 ,  0 ]\n",
      "3 : [  10 ,  10 ]\n",
      "4 : [  5 ,  0 ]\n",
      "5 : [  6 ,  10 ]\n",
      "6 : [  3 ,  5 ]\n",
      "7 : [  8 ,  5 ]\n"
     ]
    }
   ],
   "source": [
    "import openmesh as om\n",
    "\n",
    "mesh = om.read_trimesh('siete_nodos.off')\n",
    "\n",
    "V=mesh.points()\n",
    "Vx=V[:,0]\n",
    "Vy=V[:,1]\n",
    "\n",
    "for vh in mesh.vertices():\n",
    "    nVertex = vh.idx()\n",
    "    print(nVertex,': [ % .0f' % Vx[nVertex], ', % .0f' % Vy[nVertex],']')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For assembling the numerical Hamiltonian we need to access the neighboring vertices of a given vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  [1, 6, 4]\n",
      "1 :  [5, 6, 0]\n",
      "2 :  [4, 7, 3]\n",
      "3 :  [2, 7, 5]\n",
      "4 :  [0, 6, 7, 2]\n",
      "5 :  [3, 7, 6, 1]\n",
      "6 :  [7, 4, 0, 1, 5]\n",
      "7 :  [4, 6, 5, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "for vh in mesh.vertices():\n",
    "    nVertex = vh.idx()\n",
    "    \n",
    "    vlist = []\n",
    "    for vvh in mesh.vv(vh):\n",
    "        idx = vvh.idx() # devuelve indice del VERTICE\n",
    "        vlist.append(idx)\n",
    "        \n",
    "    print(nVertex,': ', vlist)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A given vertex, this radiates by the vectors that connect to the neighbor vertices. We need to calculate the angles between these common edges. Therefore, first represent the vectors that connect the given vertex to its neighbors, and then we calculate the angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : \n",
      " [[  0. -10.   0.]\n",
      " [ -3.  -5.   0.]\n",
      " [ -5.   0.   0.]] \n",
      "\n",
      "sum( [1.57 0.54 1.03] ) =  3.14 \n",
      " \n",
      "\n",
      "1 : \n",
      " [[-6.  0.  0.]\n",
      " [-3.  5.  0.]\n",
      " [ 0. 10.  0.]] \n",
      "\n",
      "sum( [1.57 1.03 0.54] ) =  3.14 \n",
      " \n",
      "\n",
      "2 : \n",
      " [[  5.   0.   0.]\n",
      " [  2.  -5.   0.]\n",
      " [  0. -10.   0.]] \n",
      "\n",
      "sum( [1.57 1.19 0.38] ) =  3.14 \n",
      " \n",
      "\n",
      "3 : \n",
      " [[ 0. 10.  0.]\n",
      " [ 2.  5.  0.]\n",
      " [ 4.  0.  0.]] \n",
      "\n",
      "sum( [1.57 0.38 1.19] ) =  3.14 \n",
      " \n",
      "\n",
      "4 : \n",
      " [[ 5.  0.  0.]\n",
      " [ 2. -5.  0.]\n",
      " [-3. -5.  0.]\n",
      " [-5.  0.  0.]] \n",
      "\n",
      "sum( [3.14 1.19 0.92 1.03] ) =  6.28 \n",
      " \n",
      "\n",
      "5 : \n",
      " [[-4.  0.  0.]\n",
      " [-2.  5.  0.]\n",
      " [ 3.  5.  0.]\n",
      " [ 6.  0.  0.]] \n",
      "\n",
      "sum( [3.14 1.19 0.92 1.03] ) =  6.28 \n",
      " \n",
      "\n",
      "6 : \n",
      " [[-5.  0.  0.]\n",
      " [-2.  5.  0.]\n",
      " [ 3.  5.  0.]\n",
      " [ 3. -5.  0.]\n",
      " [-3. -5.  0.]] \n",
      "\n",
      "sum( [1.03 1.19 0.92 2.06 1.08] ) =  6.28 \n",
      " \n",
      "\n",
      "7 : \n",
      " [[ 3.  5.  0.]\n",
      " [ 5.  0.  0.]\n",
      " [ 2. -5.  0.]\n",
      " [-2. -5.  0.]\n",
      " [-2.  5.  0.]] \n",
      "\n",
      "sum( [0.92 1.03 1.19 0.76 2.38] ) =  6.28 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "for vh in mesh.vertices():\n",
    "    nVertex = vh.idx()\n",
    "    \n",
    "    vlist = []\n",
    "    nlist = []\n",
    "    for vvh in mesh.vv(vh):\n",
    "        idx = vvh.idx() # devuelve indice del VERTICE\n",
    "        vlist.append(idx)\n",
    "        nlist.append(V[nVertex,:]-V[idx,:])\n",
    "    nlist=np.array(nlist)\n",
    "    print(nVertex,': \\n', nlist,'\\n')\n",
    "    \n",
    "    # for n in nlist:\n",
    "    THETA=[]\n",
    "    for k in range(len(nlist)):\n",
    "            v1 = nlist[k-1,:]\n",
    "            v2 = nlist[k,:]\n",
    "            theta = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "            THETA.append(theta)\n",
    "\n",
    "    THETA=np.array(THETA)            \n",
    "    print('sum(', THETA,') = % .2f' % sum(THETA),'\\n \\n')\n",
    "    # print(': [ % .0f' % THETA)\n",
    "    \n",
    "    # print(nVertex,': [ % .0f' % Vx[nVertex], ', % .0f' % Vy[nVertex],']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturrally, the number of angles is dynamic as it depends on the number of edges.\n",
    "\n",
    "\n",
    "The sum of the angles is expected to be $2\\pi$ but there is an exception or the corner points. The corner points are particular anyway, in this context (for a rectangular domain) they count with an angles $4/3$ but there is no handling of angles greater that $\\pi$ or say these angles are represented as angles $\\pi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to each triangle attached to a point, beside the angle corresponds a gradient.\n",
    "\n",
    "The vertex builds one triangle together with each of two subsequent neighbors.\n",
    "The gradient can be calculated from the function values at these three points,\n",
    "for example by the directional derivatives in the direction of the vectors of each of two connecting edges, \n",
    "\n",
    "Equivalently, the three involved points with their corresponding function values define a plan (linear function), that is defined by three parameters, where two of them correpond to the gradient.\n",
    "\n",
    "So, there are (at least) two methods to calculate the gradient from the triangle points with their respective function values. The chosen method should be a matter of taste. Problems of numerical stability should not be a concern as we assume to deal with nice triangles that count with equilibrated angles.\n",
    "\n",
    "Now, a major issuee is to get the gradient calculation not just done, but well organized, since the gradient calculation is a central task in the overall algorithm.\n",
    "\n",
    "Naturally, the gradient calculation subroutine take the information on the triangle points as input and give the gradient as output, but it is not clear in which format the input should be given, whether the actual values are given, e.g. the effective point position and the the actual function values, another more general representation, like handles to the involve triangles.\n",
    "\n",
    "The issue is that, for running any sort of optimization routine in order to solve an overall equation system, the solution variables of the equations cannot be global variables of the algoritm, but need to be handled as local variables that are transported through the subroutines. So, the function values of the nodes need to be input variables. Also we need to know at which points these function values are taken; it is sufficient to use their index values of the involved nodes are sufficent to access their corresponding positions, that are taken from a global register.\n",
    "A good question is whether to handle the subroutine parameters individually\n",
    "\n",
    "            (gx, gy) = getGradient(i1, i2, i3, u1, u2, u3)\n",
    "\n",
    "or as lists (respective arrays)\n",
    "\n",
    "            (g) = getGradient(I, U).\n",
    "\n",
    "The advantage of the handling as lists \n",
    "\n",
    "            (g) = (gx, gy),    I = (i1, i2, i3),     U = (u1, u2, u3)\n",
    "\n",
    "is their elegance in notation, but a concern is the eventual need to pack and unpack them, respective the correct handling of the lists as aglomerated data structure. For a starter we opt to use lists. (That is more involved but with the perspective to get a payout, and not postponing the need to lateron compactify the code.)\n",
    "\n",
    "The general idea of the implementation is that the three points of the triangle together with the solution values define a plane that can be described by the model\n",
    "\\begin{align*}\n",
    "    z = f(x,y) = ax + by + c,\n",
    "\\end{align*}\n",
    "where $a, b, c$ are the parameters, $x,y$ are independent variables and $z$ is a dependent variable.\n",
    "Namely for three points\n",
    "\\begin{align*}\n",
    "    (x_1, y_1, z_1) \\\\\n",
    "    (x_2, y_2, z_2) \\\\\n",
    "    (x_3, y_3, z_3)\n",
    "\\end{align*}\n",
    "inserted in the model we have the three equations\n",
    "\\begin{align*}\n",
    "    z_1 = ax_1 + by_1 + c \\\\\n",
    "    z_2 = ax_2 + by_2 + c \\\\\n",
    "    z_3 = ax_3 + by_3 + c \n",
    "\\end{align*}\n",
    "Now, if the three three-dimensional point coordinates are known, then the three parameters $a, b, c$ can be determined y solving a system of three equations with the three parameters as unknowns. Since the model is linear, we have to solve a system of linear equations\n",
    "\\begin{align*}\n",
    "    \\begin{pmatrix}\n",
    "        x_1 & y_1 & 1 \\\\\n",
    "        x_2 & y_2 & 1 \\\\\n",
    "        x_3 & y_3 & 1\n",
    "    \\end{pmatrix}    \n",
    "    \\begin{pmatrix}\n",
    "        a \\\\ b \\\\ c\n",
    "    \\end{pmatrix}    \n",
    "    =    \n",
    "    \\begin{pmatrix}\n",
    "        z_1 \\\\ z_2 \\\\ z_3\n",
    "    \\end{pmatrix},\n",
    "\\end{align*}\n",
    "that can be written in compact form as\n",
    "\\begin{align*}\n",
    "    M g = b, \\qquad\n",
    "    M = \n",
    "    \\begin{pmatrix}\n",
    "        x_1 & y_1 & 1 \\\\\n",
    "        x_2 & y_2 & 1 \\\\\n",
    "        x_3 & y_3 & 1\n",
    "    \\end{pmatrix},\n",
    "    \\qquad\n",
    "    b =\n",
    "    \\begin{pmatrix}\n",
    "        z_1 \\\\ z_2 \\\\ z_3\n",
    "    \\end{pmatrix},\n",
    "    \\qquad \n",
    "    g =\n",
    "    \\begin{pmatrix}\n",
    "        a \\\\ b \\\\ c\n",
    "    \\end{pmatrix}\n",
    "\\end{align*}\n",
    "The matrix $M$ can be assembled by the point positions, the vector $b$ consists of the function values, and the searched vector $g$ contains the parameters $a,b,c$. So, the parameters can be calculated by solving the linear system of equations.\n",
    "\n",
    "The gradient \n",
    "\\begin{align*}\n",
    "    \\nabla f(x,y) = \\Biggl( \\frac{\\partial f(x,y)}{\\partial x} , \\frac{\\partial f(x,y)}{\\partial y} \\Biggr)\n",
    "\\end{align*}\n",
    "of the plane described by the model is obtained by calculating the partial derivatives\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial f(x,y)}{\\partial x} = \\frac{\\partial}{\\partial x} ( ax + by + c) = a \\\\\n",
    "    \\frac{\\partial f(x,y)}{\\partial y} = \\frac{\\partial}{\\partial y} ( ax + by + c) = b \n",
    "\\end{align*}\n",
    "This means that the gradient is given by the parameters as\n",
    "\\begin{align*}\n",
    "    \\nabla f(x,y) = (a, b)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alternative implementation based on the directional derivatives actually might also start with the three points.\n",
    "Actually the directional derivatives migth be expressed in terms of the three points as\n",
    "\\begin{align*}\n",
    "    x_a = x_2 - x_1, \\qquad y_a = x_2 - x_1, \\qquad, z_a = z_2 - z_1,\n",
    "    x_b = x_3 - x_1, \\qquad y_b = x_3 - x_1, \\qquad, z_b = z_3 - z_1,\n",
    "\\end{align*}\n",
    "i. e. the derivative in direction $(x_a, y_a)$ is $z_a$ and in direction $(x_b, y_b)$ it is $z_b$.\n",
    "\n",
    "Now, an interpretation of the gradient in the coordinates of directional derivatives is that the gradient of the model of the plane that \n",
    "passes through the points $(x_a, y_a, z_a)$, $(x_b, y_b, z_b)$ and the origin $(0, 0, 0)$.\n",
    "\n",
    "In terms of a 3-dimensional model\n",
    "\\begin{align*}\n",
    "    z = a x + b y + c\n",
    "\\end{align*}\n",
    "by inserting the origin we have that $c=0$, which is no surprise as the plan is passing through the origin.\n",
    "The remaining model for the two remaining points is \n",
    "\\begin{align*}\n",
    "    z = a x + b y\n",
    "\\end{align*}\n",
    "Inserting gives\n",
    "\\begin{align*}\n",
    "    z_a = a x_a + b y_a, \\\\\n",
    "    z_b = a x_b + b y_b,\n",
    "\\end{align*}\n",
    "so we have two equations for the two still unknown parameters $a,b,$,\n",
    "that can be written as\n",
    "\\begin{align*}\n",
    "    \\begin{pmatrix}\n",
    "        x_a & y_a \\\\\n",
    "        x_b & y_b\n",
    "    \\end{pmatrix}    \n",
    "    \\begin{pmatrix}\n",
    "        a \\\\ b\n",
    "    \\end{pmatrix}    \n",
    "    =    \n",
    "    \\begin{pmatrix}\n",
    "        z_a \\\\ z_b\n",
    "    \\end{pmatrix},\n",
    "\\end{align*}\n",
    "which in terms of the original points is\n",
    "\\begin{align*}\n",
    "    \\begin{pmatrix}\n",
    "        x_2 - x_1 & y_2 - x_1 \\\\\n",
    "        x_3 - x_1 & y_3 - x_1        \n",
    "    \\end{pmatrix}    \n",
    "    \\begin{pmatrix}\n",
    "        a \\\\ b\n",
    "    \\end{pmatrix}    \n",
    "    =\n",
    "    \\begin{pmatrix}\n",
    "        z_2 - z_1 \\\\ \n",
    "        z_3 - z_1\n",
    "    \\end{pmatrix},\n",
    "\\end{align*}\n",
    "\n",
    "Now we are ready for the implementation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g2: [[-0.02]\n",
      " [ 0.09]] \n",
      " \n",
      " g3: [[-0.02]\n",
      " [ 0.09]]\n"
     ]
    }
   ],
   "source": [
    "def getGradent(I, U):\n",
    "    m = np.zeros((3, 3))\n",
    "    b = np.zeros((3, 1))\n",
    "\n",
    "    for k in range(3):\n",
    "        # print(k)\n",
    "        m[k,0] = V[I[k],0]\n",
    "        m[k,1] = V[I[k],1]\n",
    "        m[k,2] = 1\n",
    "        b[k] = U[k]\n",
    "                \n",
    "    g = np.linalg.solve(m, b)    \n",
    "    \n",
    "    return g[0:2]\n",
    "\n",
    "def getGradent2(I, U):\n",
    "    m = np.zeros((2, 2))\n",
    "    b = np.zeros((2, 1))\n",
    "\n",
    "    for k in range(2):\n",
    "        m[k,0] = V[I[k+1],0]-V[I[0],0]\n",
    "        m[k,1] = V[I[k+1],1]-V[I[0],1]\n",
    "        b[k] = U[k+1]-U[0]\n",
    "                \n",
    "    g = np.linalg.solve(m, b)    \n",
    "    \n",
    "    return g\n",
    "\n",
    "I = [4, 6, 7]\n",
    "U = [2, 2.5, 2.4]\n",
    "g3 = getGradent(I, U)\n",
    "g2 = getGradent2(I, U)\n",
    "print('g2:', g2, '\\n \\n g3:',g3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the code for the calculation of the gradient implemented, how does it apply for the overall iteration? The gradients should be handled in parallel to the angles.  Therefore the input argument should be prepared.\n",
    "\n",
    "The function values are generated from a predefined function. From a list of neighboring vertices we extract all index pairs of subsequent vertices, and generate list of index triples.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vlist: [4, 6, 5, 3, 2] ; \t T: [  0.    0.   15.  415.    7.5 249.   27.   72. ] ; \t T[vlist]:  [  7.5  27.  249.  415.   15. ] \n",
      "\n",
      "\n",
      "g[ [7, 2, 4] ] =  [[ 1.5 12. ]]\n",
      "g[ [7, 4, 6] ] =  [[9.  7.5]]\n",
      "g[ [7, 6, 5] ] =  [[ 9. 39.]]\n",
      "g[ [7, 5, 3] ] =  [[41.5 52. ]]\n",
      "g[ [7, 3, 2] ] =  [[71.5 40. ]]\n"
     ]
    }
   ],
   "source": [
    "def getT(x,y):\n",
    "    return x*(1+0.5*(1-y)**2)\n",
    "\n",
    "T = getT(V[:,0],V[:,1])\n",
    "\n",
    "print('vlist:',vlist,'; \\t T:',T,'; \\t T[vlist]: ', T[vlist], '\\n\\n')\n",
    "for k in range(len(vlist)):\n",
    "    I=[nVertex, vlist[k-1], vlist[k]]\n",
    "    g = getGradent2(I, T[I])\n",
    "    print('g[', I, '] = ', g.transpose())\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This procedure can be plugged into the iteration, but there is one detail: Does the calculation effectively allways work, or are there cases where the procedure breaks down, which is manifested by an error message on a singular matrix.\n",
    "\n",
    "If the directial derivative are in (nearly) colinear direction, \n",
    "i.e. the three chosen points are positioned on the same line, the matrix becomes singular.\n",
    "This is manifested by an either small angle $\\theta \\approx 0$ or an angle that is close to $\\pi$. (Angles greater than $\\pi$ do not occur by definition.)\n",
    "\n",
    "\n",
    "Though we assume and have nice triangles in the interior of the domain, small angles effectively occur for points at the boundary, where angles $\\theta = \\pi$ appear naturally at boundaries that are straight lines. So, these cases need to be captured. But what should we do then, what is the interpretation? In this case there is just no gradient to calculate, to there is also no need to register the angle.\n",
    "\n",
    "From a systematic point of view, as this happens with boundary vertices, should be an extra treatment? All nodes have a contribution to the overall equation system. However, the outer angles that cover an area outside the domain do not contribute to an average gradient. this also happens for corner points, where to neigborss are connected by an angle of $\\theta = \\pi/2$.\n",
    "\n",
    "The triangle of points define a plane, and interestingly, the corresponding gradient should be rather similar to the other calculated gradients, so it won't affect the calculation much when included.\n",
    "\n",
    "Anyway, all list excercise is done to obtain the information on angles and gradients, with the perspective to calculate the numerical Hamiltonian by a weighting rule. Since this information is dynamic, with varying length of the object, it is not too convenient to export this information to a superior subroutine, but should be done in place.\n",
    "\n",
    "As intermedate excercise we calculate the average of the gradient for each considered central vertex as\n",
    "\\begin{align*}\n",
    "    \\bar{G} = \\frac{\\sum_{k=0}^N \\theta_k g_k}{\\sum_{k=0}^{N} \\theta_k}\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : \n",
      " [[  0. -10.   0.]\n",
      " [ -3.  -5.   0.]\n",
      " [ -5.   0.   0.]] \n",
      "\n",
      "\t \t \t \t \t theta[ [0, 4, 1] ] =  1.5707963267948966\n",
      "g[ [0, 1, 6] ] =  [[9. 0.]] \t \t theta[ [0, 1, 6] ] =  0.5404195002705842\n",
      "g[ [0, 6, 4] ] =  [[1.5 4.5]] \t \t theta[ [0, 6, 4] ] =  1.0303768265243125\n",
      "sum( [0.54 1.03] ) =  1.57 \n",
      " \n",
      "\n",
      "GRADIENT: [[[9. ]\n",
      "  [0. ]]\n",
      "\n",
      " [[1.5]\n",
      "  [4.5]]] \n",
      " \n",
      "\n",
      "1 : \n",
      " [[-6.  0.  0.]\n",
      " [-3.  5.  0.]\n",
      " [ 0. 10.  0.]] \n",
      "\n",
      "\t \t \t \t \t theta[ [1, 0, 5] ] =  1.5707963267948966\n",
      "g[ [1, 5, 6] ] =  [[41.5 19.5]] \t \t theta[ [1, 5, 6] ] =  1.0303768265243125\n",
      "g[ [1, 6, 0] ] =  [[ 9. -0.]] \t \t theta[ [1, 6, 0] ] =  0.5404195002705842\n",
      "sum( [1.03 0.54] ) =  1.57 \n",
      " \n",
      "\n",
      "GRADIENT: [[[41.5]\n",
      "  [19.5]]\n",
      "\n",
      " [[ 9. ]\n",
      "  [-0. ]]] \n",
      " \n",
      "\n",
      "2 : \n",
      " [[  5.   0.   0.]\n",
      " [  2.  -5.   0.]\n",
      " [  0. -10.   0.]] \n",
      "\n",
      "\t \t \t \t \t theta[ [2, 3, 4] ] =  1.5707963267948966\n",
      "g[ [2, 4, 7] ] =  [[ 1.5 12. ]] \t \t theta[ [2, 4, 7] ] =  1.1902899496825317\n",
      "g[ [2, 7, 3] ] =  [[71.5 40. ]] \t \t theta[ [2, 7, 3] ] =  0.3805063771123649\n",
      "sum( [1.19 0.38] ) =  1.57 \n",
      " \n",
      "\n",
      "GRADIENT: [[[ 1.5]\n",
      "  [12. ]]\n",
      "\n",
      " [[71.5]\n",
      "  [40. ]]] \n",
      " \n",
      "\n",
      "3 : \n",
      " [[ 0. 10.  0.]\n",
      " [ 2.  5.  0.]\n",
      " [ 4.  0.  0.]] \n",
      "\n",
      "\t \t \t \t \t theta[ [3, 5, 2] ] =  1.5707963267948966\n",
      "g[ [3, 2, 7] ] =  [[71.5 40. ]] \t \t theta[ [3, 2, 7] ] =  0.3805063771123649\n",
      "g[ [3, 7, 5] ] =  [[41.5 52. ]] \t \t theta[ [3, 7, 5] ] =  1.1902899496825317\n",
      "sum( [0.38 1.19] ) =  1.57 \n",
      " \n",
      "\n",
      "GRADIENT: [[[71.5]\n",
      "  [40. ]]\n",
      "\n",
      " [[41.5]\n",
      "  [52. ]]] \n",
      " \n",
      "\n",
      "4 : \n",
      " [[ 5.  0.  0.]\n",
      " [ 2. -5.  0.]\n",
      " [-3. -5.  0.]\n",
      " [-5.  0.  0.]] \n",
      "\n",
      "\t \t \t \t \t theta[ [4, 2, 0] ] =  3.141592653589793\n",
      "g[ [4, 0, 6] ] =  [[1.5 4.5]] \t \t theta[ [4, 0, 6] ] =  1.1902899496825317\n",
      "g[ [4, 6, 7] ] =  [[9.  7.5]] \t \t theta[ [4, 6, 7] ] =  0.9209258773829491\n",
      "g[ [4, 7, 2] ] =  [[ 1.5 12. ]] \t \t theta[ [4, 7, 2] ] =  1.0303768265243125\n",
      "sum( [1.19 0.92 1.03] ) =  3.14 \n",
      " \n",
      "\n",
      "GRADIENT: [[[ 1.5]\n",
      "  [ 4.5]]\n",
      "\n",
      " [[ 9. ]\n",
      "  [ 7.5]]\n",
      "\n",
      " [[ 1.5]\n",
      "  [12. ]]] \n",
      " \n",
      "\n",
      "5 : \n",
      " [[-4.  0.  0.]\n",
      " [-2.  5.  0.]\n",
      " [ 3.  5.  0.]\n",
      " [ 6.  0.  0.]] \n",
      "\n",
      "\t \t \t \t \t theta[ [5, 1, 3] ] =  3.141592653589793\n",
      "g[ [5, 3, 7] ] =  [[41.5 52. ]] \t \t theta[ [5, 3, 7] ] =  1.1902899496825317\n",
      "g[ [5, 7, 6] ] =  [[ 9. 39.]] \t \t theta[ [5, 7, 6] ] =  0.9209258773829491\n",
      "g[ [5, 6, 1] ] =  [[41.5 19.5]] \t \t theta[ [5, 6, 1] ] =  1.0303768265243125\n",
      "sum( [1.19 0.92 1.03] ) =  3.14 \n",
      " \n",
      "\n",
      "GRADIENT: [[[41.5]\n",
      "  [52. ]]\n",
      "\n",
      " [[ 9. ]\n",
      "  [39. ]]\n",
      "\n",
      " [[41.5]\n",
      "  [19.5]]] \n",
      " \n",
      "\n",
      "6 : \n",
      " [[-5.  0.  0.]\n",
      " [-2.  5.  0.]\n",
      " [ 3.  5.  0.]\n",
      " [ 3. -5.  0.]\n",
      " [-3. -5.  0.]] \n",
      "\n",
      "g[ [6, 5, 7] ] =  [[ 9. 39.]] \t \t theta[ [6, 5, 7] ] =  1.0303768265243125\n",
      "g[ [6, 7, 4] ] =  [[9.  7.5]] \t \t theta[ [6, 7, 4] ] =  1.1902899496825317\n",
      "g[ [6, 4, 0] ] =  [[1.5 4.5]] \t \t theta[ [6, 4, 0] ] =  0.9209258773829491\n",
      "g[ [6, 0, 1] ] =  [[9. 0.]] \t \t theta[ [6, 0, 1] ] =  2.060753653048625\n",
      "g[ [6, 1, 5] ] =  [[41.5 19.5]] \t \t theta[ [6, 1, 5] ] =  1.0808390005411683\n",
      "sum( [1.03 1.19 0.92 2.06 1.08] ) =  6.28 \n",
      " \n",
      "\n",
      "GRADIENT: [[[ 9. ]\n",
      "  [39. ]]\n",
      "\n",
      " [[ 9. ]\n",
      "  [ 7.5]]\n",
      "\n",
      " [[ 1.5]\n",
      "  [ 4.5]]\n",
      "\n",
      " [[ 9. ]\n",
      "  [ 0. ]]\n",
      "\n",
      " [[41.5]\n",
      "  [19.5]]] \n",
      " \n",
      "\n",
      "7 : \n",
      " [[ 3.  5.  0.]\n",
      " [ 5.  0.  0.]\n",
      " [ 2. -5.  0.]\n",
      " [-2. -5.  0.]\n",
      " [-2.  5.  0.]] \n",
      "\n",
      "g[ [7, 2, 4] ] =  [[ 1.5 12. ]] \t \t theta[ [7, 2, 4] ] =  0.9209258773829491\n",
      "g[ [7, 4, 6] ] =  [[9.  7.5]] \t \t theta[ [7, 4, 6] ] =  1.0303768265243125\n",
      "g[ [7, 6, 5] ] =  [[ 9. 39.]] \t \t theta[ [7, 6, 5] ] =  1.1902899496825317\n",
      "g[ [7, 5, 3] ] =  [[41.5 52. ]] \t \t theta[ [7, 5, 3] ] =  0.7610127542247296\n",
      "g[ [7, 3, 2] ] =  [[71.5 40. ]] \t \t theta[ [7, 3, 2] ] =  2.3805798993650638\n",
      "sum( [0.92 1.03 1.19 0.76 2.38] ) =  6.28 \n",
      " \n",
      "\n",
      "GRADIENT: [[[ 1.5]\n",
      "  [12. ]]\n",
      "\n",
      " [[ 9. ]\n",
      "  [ 7.5]]\n",
      "\n",
      " [[ 9. ]\n",
      "  [39. ]]\n",
      "\n",
      " [[41.5]\n",
      "  [52. ]]\n",
      "\n",
      " [[71.5]\n",
      "  [40. ]]] \n",
      " \n",
      "\n",
      "\n",
      " \n",
      " -------- List of average gradients ------- \n",
      " \n",
      " [[[ 4.08  2.95]]\n",
      "\n",
      " [[30.32 12.79]]\n",
      "\n",
      " [[18.46 18.78]]\n",
      "\n",
      " [[48.77 49.09]]\n",
      "\n",
      " [[ 3.7   7.84]]\n",
      "\n",
      " [[31.97 37.53]]\n",
      "\n",
      " [[13.49 11.83]]\n",
      "\n",
      " [[35.52 31.83]]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "Glist = []\n",
    "    \n",
    "for vh in mesh.vertices():\n",
    "    nVertex = vh.idx()\n",
    "    \n",
    "    vlist = []\n",
    "    nlist = []\n",
    "    \n",
    "    for vvh in mesh.vv(vh):\n",
    "        idx = vvh.idx() # devuelve indice del VERTICE\n",
    "        vlist.append(idx)\n",
    "        nlist.append(V[nVertex,:]-V[idx,:])\n",
    "    nlist=np.array(nlist)\n",
    "    print(nVertex,': \\n', nlist,'\\n')\n",
    "    \n",
    "    # for n in nlist:\n",
    "    THETA=[]\n",
    "    GRADIENT=[]\n",
    "    for k in range(len(vlist)):\n",
    "            v1 = nlist[k-1,:]\n",
    "            v2 = nlist[k,:]\n",
    "            theta = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "            I=[nVertex, vlist[k-1], vlist[k]]\n",
    "            \n",
    "            if (abs(theta)<math.pi-1e-3) and (abs(theta) > 1e-3) and (abs(theta-math.pi/2)>1e-3):\n",
    "                g = getGradent2(I, T[I])\n",
    "                THETA.append(theta)\n",
    "                GRADIENT.append(g)\n",
    "                print('g[', I, '] = ', g.transpose(), '\\t \\t theta[', I, '] = ', theta)\n",
    "            else:\n",
    "                print('\\t \\t \\t \\t \\t theta[', I, '] = ', theta)\n",
    "\n",
    "    THETA=np.array(THETA)  \n",
    "    GRADIENT=np.array(GRADIENT)\n",
    "    print('sum(', THETA,') = % .2f' % sum(THETA),'\\n \\n')\n",
    "    print('GRADIENT:', GRADIENT,'\\n \\n') # = % .2f') #  % sum(GRADIENT),'\\n \\n')\n",
    "    gav = GRADIENT.transpose().dot(THETA)/sum(THETA)\n",
    "    Glist.append(gav)\n",
    "  \n",
    "    \n",
    "Glist = np.array(Glist)\n",
    "print('\\n \\n -------- List of average gradients ------- \\n \\n', Glist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it comes to effectively calculate the numerical Hamiltonian. As a basic ingredient we define the sample Hamiltonian as the norm of the gradient,\n",
    "\\begin{align*}\n",
    "    H(U) = H(\\nabla U) = \\| \\nabla U \\|_2 = \\| U_x + U_y \\|_2\n",
    "\\end{align*}\n",
    "[Is it a function of $U$ or of $\\nabla U$?] Going back to the basic and ultimate ingredients, it is a function of $U$. But as the charateristic part of the processing, it is a function of $\\nabla U$, so from a mathical point of view we have $H=H(\\nabla U)$, but for a betta data structure handle we use $H=H(U)$.\n",
    "\n",
    "As each equation is associated to a vertex, so each elemental evaluation of a Hamiltonian should be associated to a vertex. Then the generation of the residual as a discretization of the governing equations run over all vertices, calling each single elemental evaluation of a Hamiltonian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the inputs needed such then adaptions can be done just by changing the implementation of the model, but not too many parts of the overall code. The plan is too prepare the overall algorithm as general as possible in order to allow to run over a broad range of model specification without some major need to dig into implemenation details.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.001249804748511\n"
     ]
    }
   ],
   "source": [
    "# ... should be revised ...\n",
    "\n",
    "def hamiltonian(U):\n",
    "    return np.linalg.norm(U)\n",
    "\n",
    "UU=np.array([[1, 2], [3, 4], [5, 6]])\n",
    "h=hamiltonian(U)\n",
    "print(h) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the previous implementation is cleaned up by putting all specifics that correspond to a specific vertex into a subroutine, that can be called through an overall routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nVertex: 7\n",
      "\n",
      " sum( [0.92 1.03 1.19 0.76 2.38] ) =  6.28 \n",
      " \n",
      "\n",
      "GRADIENT: \n",
      " [[[ 1.5  9.   9.  41.5 71.5]\n",
      "  [12.   7.5 39.  52.  40. ]]] \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_theta_gradient(vh):\n",
    "    nVertex = vh.idx()\n",
    "    \n",
    "    vlist = []\n",
    "    nlist = []    \n",
    "    \n",
    "    for vvh in mesh.vv(vh):\n",
    "        idx = vvh.idx() # devuelve indice del VERTICE\n",
    "        vlist.append(idx)\n",
    "        nlist.append(V[nVertex,:]-V[idx,:])\n",
    "    nlist=np.array(nlist)\n",
    "    # print(nVertex,': \\n', nlist,'\\n')\n",
    "    \n",
    "    # for n in nlist:\n",
    "    THETA=[]\n",
    "    GRADIENT=[]\n",
    "    for k in range(len(vlist)):\n",
    "            v1 = nlist[k-1,:]\n",
    "            v2 = nlist[k,:]\n",
    "            theta = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "            I=[nVertex, vlist[k-1], vlist[k]]                \n",
    "                \n",
    "            if (abs(theta)<math.pi-1e-3) and (abs(theta) > 1e-3) and (abs(theta-math.pi/2)>1e-3):\n",
    "                g = getGradent2(I, T[I])\n",
    "                THETA.append(theta)\n",
    "                GRADIENT.append(g)\n",
    "                \n",
    "    THETA=np.array(THETA)  \n",
    "    GRADIENT=np.array(GRADIENT)\n",
    "\n",
    "    return THETA, GRADIENT\n",
    "\n",
    "print('nVertex:', vh.idx())\n",
    "theta, gradient = get_theta_gradient(vh)\n",
    "\n",
    "print('\\n sum(', THETA,') = % .2f' % sum(THETA),'\\n \\n')\n",
    "print('GRADIENT: \\n', GRADIENT.transpose(),'\\n \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet, the assembling of the numerical Hamiltonian should be done in an intermediate subroutine, as there are different choices of how to handle the gradient and angle information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35.52 31.83]]\n"
     ]
    }
   ],
   "source": [
    "def ham(vh): \n",
    "    theta, gradient = get_theta_gradient(vh)\n",
    "    gav = gradient.transpose().dot(theta)/sum(theta)\n",
    "    \n",
    "    return gav\n",
    "\n",
    "gav = ham(vh)\n",
    "print(gav)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This re-organization of the implemenation allows us to call subroutine for the numerical Hamiltonian in a compact way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " -------- List of average gradients ------- \n",
      " \n",
      " [[[ 4.08  2.95]]\n",
      "\n",
      " [[30.32 12.79]]\n",
      "\n",
      " [[18.46 18.78]]\n",
      "\n",
      " [[48.77 49.09]]\n",
      "\n",
      " [[ 3.7   7.84]]\n",
      "\n",
      " [[31.97 37.53]]\n",
      "\n",
      " [[13.49 11.83]]\n",
      "\n",
      " [[35.52 31.83]]]\n"
     ]
    }
   ],
   "source": [
    "Glist = []\n",
    "for vh in mesh.vertices():\n",
    "        \n",
    "    gav = ham(vh)\n",
    "    Glist.append(gav)\n",
    "  \n",
    "    \n",
    "Glist = np.array(Glist)\n",
    "print('\\n \\n -------- List of average gradients ------- \\n \\n', Glist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet we did not calculate a Hamiltonian different to the identical function that gives an averaged gradient. But with the established procedure, that is now organized in different subroutines, we are in the position to start with the adaptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we start to get more involved by defining a local mode parameter, that enables us to control the possibles choices about the Hamiltonian in a systematic way. This saves us from an explosion of different subroutines to handle the Hamiltonian for different choices. Instead the switch to the different choice is done by the mode parameter. This allows a systematic run over the choices in sequence or in parrallel.\n",
    "\n",
    "The different choices include different options for the numerical Hamiltonian and different modelos of the physical Hamiltonian.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now, effectively pointing to the considered models, namely\n",
    "\\begin{align*}\n",
    "   H_T(T, S) = \\| \\nabla T \\| - v = 0 ,\n",
    "   H_S(T, S) = \\frac{\\nabla T}{\\| \\nabla T \\|} - \\nabla S ,\n",
    "\\end{align*}\n",
    "we recognize that additional data formats and specifications are required.\n",
    "\n",
    "\n",
    "The equation\n",
    "\\begin{align*}\n",
    "    \\frac{\\nabla T}{\\| \\nabla T \\|} = \\nabla S\n",
    "\\end{align*}\n",
    "actually represents two equations,\n",
    "where it is not clear what is the transient equation extention, to that\n",
    "it represents the stationary case. Maybe something like\n",
    "\\begin{align*}\n",
    "    T_t (1, 1) + \\frac{\\nabla T}{\\| \\nabla T \\|} = \\nabla S\n",
    "\\end{align*}\n",
    "[One variable, two equations: Can this work?]\n",
    "\n",
    "Anyway, the two equations are \n",
    "\\begin{align*}\n",
    "    \\frac{T_x}{\\| \\nabla T \\|} = \\nabla S_x \\\\\n",
    "    \\frac{T_y}{\\| \\nabla T \\|} = \\nabla S_y,\n",
    "\\end{align*}\n",
    "so a numerical Hamiltonian should be designed for each of them.\n",
    "\n",
    "[In total we have 3 equation for each vertex, but still two variables.]\n",
    "\n",
    "The issue is the general variable handling.\n",
    "As the solution variables $T, S$ are used within the calculation of the Hamiltionian,\n",
    "they should be input parameters of the subroutine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿How to include T, S?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-34.77 -31.16]]\n"
     ]
    }
   ],
   "source": [
    "# def velocity(vh, S):\n",
    "#    print('should ...')\n",
    "#    print('...not outsource by now...')\n",
    "#    return 1\n",
    "\n",
    "def hamiltonian(vh, T):\n",
    "    nVertex = vh.idx()\n",
    "    theta, gradient = get_theta_gradient(vh)\n",
    "    gav = gradient.transpose().dot(theta)/sum(theta)\n",
    "    \n",
    "    # print(mode)\n",
    "    \n",
    "    if mode =='1':\n",
    "        H = np.linalg.norm(gav)\n",
    "    elif mode == 'hamT':\n",
    "        Tgav = gav\n",
    "        # H = np.linalg.norm(Tgav) - velocity(vh)\n",
    "        H = np.linalg.norm(Tgav) - V[nVertex,1]/(S[nVertex]+1e-5)\n",
    "    elif mode == 'hamS':\n",
    "        Tgav = gav\n",
    "        Sgav = gav\n",
    "        H = Tgav / np.linalg.norm(Tgav) - Sgav\n",
    "    else:\n",
    "        'ERR: mode is not defined'\n",
    "    \n",
    "    return H\n",
    "\n",
    "mode = '1'\n",
    "mode = 'hamT'\n",
    "mode = 'hamS'\n",
    "\n",
    "H = hamiltonian(vh, T)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  47.69319485752732\n",
      "hamT :  47.62375042272793\n",
      "hamS :  [[-34.77 -31.16]]\n"
     ]
    }
   ],
   "source": [
    "MODES = ['1', 'hamT', 'hamS']\n",
    "\n",
    "T = getT(V[:,0],V[:,1])\n",
    "S = getT(V[:,0],V[:,1])\n",
    "\n",
    "for mode in MODES:\n",
    "    # print(mode)\n",
    "    H = hamiltonian(vh, T)\n",
    "    print(mode,': ',H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and use more geometry\n",
    "\n",
    "\n",
    "The directions of the directional derivatives\n",
    "\\begin{align*}\n",
    "    d_i = v_0 - v_i, \\qquad i = 1,\n",
    "\\end{align*}\n",
    "indicate the directions of the neighbor vertices towards the considered center node.\n",
    "Each attached triangle counts with average nodes\n",
    "\\begin{align*}\n",
    "    v_{i+1/2} = \\frac{1}{2} (v_i + v_{i_1})\n",
    "\\end{align*}\n",
    "and an average direction\n",
    "\\begin{align*}\n",
    "    n_{i+1/2} = \\frac{1}{2} (d_i + d_{i_1}) = v_0 - \\frac{v_i + v_{i+1}}{2} = v_0 - v_{i+1/2} . \n",
    "\\end{align*}\n",
    "As the gradients are given as in between, with the dot product\n",
    "\\begin{align*}\n",
    "    n_{i+1/2} \\cdot g_{i+1/2}\n",
    "\\end{align*}\n",
    "it can be determined whether a gradient is ingoing or outgoing.\n",
    "\n",
    "As we want to focus on the ingoing gradients,\n",
    "and in turn weight the grade of ingoingness,\n",
    "we can define the ponderations as\n",
    "\\begin{align*}\n",
    "    \\tilde{p}_{i+1/2}\n",
    "    = n_{i+1/2} \\cdot g_{i+1/2} . \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "### [!] variable status of Thalf: where defined?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vhalf: \n",
      " [[6.5 5.5 7.  9.  9. ]\n",
      " [2.5 5.  7.5 7.5 2.5]\n",
      " [0.  0.  0.  0.  0. ]] \n",
      "\n",
      "\n",
      "nhalf: \n",
      " [[ 0.5  4.   3.5  0.  -2. ]\n",
      " [ 5.   2.5 -2.5 -5.   0. ]\n",
      " [ 0.   0.   0.   0.   0. ]] \n",
      "\n",
      "Thalf: \n",
      " [ 39.75  49.5  160.5  243.5   43.5 ] \n",
      "\n",
      "Tsort:    [3 2 1 4 0]   \t Tlist \t [  7.5  27.  249.  415.   15. ]\n",
      "ng_sort:  [[3 4 2 1 0]] \t ng: \t [[  60.75   54.75  -66.   -260.   -143.  ]]\n"
     ]
    }
   ],
   "source": [
    "def moreGeometry(vh):\n",
    "    nVertex = vh.idx()\n",
    "    \n",
    "    vlist = []\n",
    "    nlist = []\n",
    "    vhalf = []\n",
    "    nhalf = []\n",
    "    Thalf = []\n",
    "    \n",
    "    for vvh in mesh.vv(vh):\n",
    "        idx = vvh.idx() # devuelve indice del VERTICE\n",
    "        vlist.append(idx)\n",
    "        nlist.append(V[nVertex,:]-V[idx,:])\n",
    "        vhalf.append((V[nVertex,:]+V[idx,:])/2)\n",
    "        Thalf.append((T[nVertex]+T[idx])/2)\n",
    "        \n",
    "    nlist = np.array(nlist)\n",
    "    vhalf = np.array(vhalf)\n",
    "    Thalf = np.array(Thalf)\n",
    "    \n",
    "    for k in range(len(vlist)):\n",
    "            n1 = nlist[k-1,:]\n",
    "            n2 = nlist[k,:]\n",
    "            nhalf.append((n1+n2)/2)\n",
    "                \n",
    "    nhalf = np.array(nhalf)\n",
    "\n",
    "    return vhalf, nhalf, Thalf\n",
    "\n",
    "vhalf, nhalf, Thalf = moreGeometry(vh)\n",
    "print('vhalf: \\n', vhalf.transpose(), '\\n\\n')\n",
    "print('nhalf: \\n', nhalf.transpose(),'\\n')\n",
    "print('Thalf: \\n', Thalf.transpose(),'\\n')\n",
    "\n",
    "\n",
    "ng=[]\n",
    "theta, gradient = get_theta_gradient(vh)\n",
    "for k in range(len(nhalf)):\n",
    "    ng.append(np.dot(gradient[k].transpose(), nhalf[k,0:2]))\n",
    "\n",
    "ng=np.array(ng).transpose()\n",
    "\n",
    "Tsort = np.argsort(-T[vlist])\n",
    "ng_sort = np.argsort(ng)\n",
    "\n",
    "print('Tsort:   ', Tsort, '  \\t Tlist \\t', T[vlist])\n",
    "print('ng_sort: ', ng_sort, '\\t ng: \\t', ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngs = np.argsort(ng, axis=1, kind='quicksort', order=None)\n",
    "ngs = np.argsort(ng)\n",
    "k=np.argmax(ng)\n",
    "k=np.argmin(ng)\n",
    "z=np.max(ng)\n",
    "T\n",
    "T[vlist]\n",
    "T[vlist[np.argmax(ng)]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the used directions (from which the information is taken) the choice is somehow between taking the extreme values, or do some weighting.\n",
    "\n",
    "One approach is to choose some reference value\n",
    "\\begin{align*}\n",
    "    \\bar{T} = (1 - \\alpha) T_{argsort(1)} + \\alpha T_{argsort(-1)} ,\n",
    "\\end{align*}\n",
    "such that the weights are \n",
    "\\begin{align*}\n",
    "    p_i = \\frac{\\tilde{p_i}}{\\sum_{i=0}^K \\tilde{p_i}} ,\n",
    "    \\qquad\n",
    "    \\tilde{p}_i = (\\bar{T} - T_i)^+ .\n",
    "\\end{align*}\n",
    "\n",
    "For $\\alpha = 0$ there would be all weight in one single position, whereas for $\\alpha \\rightarrow -\\infty$ there would be an equidistribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tlist=T[vlist]\n",
    "Tsort = np.sort(Tlist)\n",
    "# alpha = 1\n",
    "# alpha = -1\n",
    "alpha = 0\n",
    "alpha = 0.2\n",
    "# alpha = 0.5\n",
    "Tmean = (1-alpha)*Tsort[-1] + alpha*Tsort[1]\n",
    "Tplus = np.maximum(Tmean - Tlist, 0)\n",
    "p = Tplus/sum(Tplus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the gradient of each triangle known, also the constant $c_{i+1/2}$ associated to that triangle can be calculated by using the information of the solution value at the intermediate vertex as\n",
    "\\begin{align*}\n",
    "    c_{i+1/2} = S_{i+1/2} - a_{i+1/2} x_{i+1/2} - b_{i+1/2} y_{i+1/2}\n",
    "\\end{align*}\n",
    "[Now change to $S$ and the normalized $\\nabla S$; it was ok to calculate the weights by the comparison of $T$ values, as they are more stable / independend, but now the equation has to focus on $S$.]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 36.46]\n",
      " [ 42.07]\n",
      " [151.62]\n",
      " [232.02]\n",
      " [ 34.42]]\n"
     ]
    }
   ],
   "source": [
    "# ahalf[l] = gradient[k,0]\n",
    "chalf=[]\n",
    "for k in range(len(vhalf)):\n",
    "    g = gradient[k]\n",
    "    g = g/np.linalg.norm(g)\n",
    "    c = Thalf[k] - np.dot(g.transpose(), vhalf[k,0:2])\n",
    "    chalf.append(c)\n",
    "    \n",
    "chalf = np.array(chalf)\n",
    "print(chalf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    \\bar{S}_0 - S_0 = 0 \\\\\n",
    "    \\bar{S}_0 = \\sum_{i=0}^K  p_i \\bigl( \n",
    "        a_{i+1/2} x_{0} + b_{i+1/2} y_{0} + c_{i+1/2}\n",
    "    \\bigr)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "ahalf=gradient[:,0]\n",
    "bhalf=gradient[:,1]\n",
    "gnorm=(ahalf**2+bhalf**2)**(0.5)\n",
    "ahalf=ahalf/gnorm\n",
    "bhalf=bhalf/gnorm\n",
    "SS=ahalf*V[nVertex,0]+bhalf*V[nVertex,1]+chalf\n",
    "Sbar = np.dot(p,SS)\n",
    "\n",
    "print(Sbar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we turn back to the general view with the overall iteration, and put all encountered features into it.\n",
    "\n",
    "The general routine calculates the residual, as two equations for each vertex. \n",
    "\n",
    "For starting the iterations we need an an initial guess for the solution components,\n",
    "that also need to be consistent with the boundary conditions. One suggestion is\n",
    "\\begin{align*}\n",
    "    T(x,y) = x \\Biggl( 1 + \\frac{1}{2}(1-y)^2 \\Biggr), \\qquad\n",
    "\\end{align*}\n",
    "which keeps track with\n",
    "\\begin{align*}\n",
    "    T(x=0, y) =0, \\qquad T(x, y=1) = x\n",
    "\\end{align*}\n",
    "and\n",
    "\\begin{align*}\n",
    "    S(x,y) = x (1-y), \\qquad\n",
    "\\end{align*}\n",
    "which keeps track with\n",
    "\\begin{align*}\n",
    "    S(x=0, y) =0, \\qquad S(x, y=1) = 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_T(x,y):\n",
    "    return x*(1+0.5*(1-y)**2)\n",
    "\n",
    "def get_S(x,y):\n",
    "    return x*(1-y)\n",
    "\n",
    "T=get_T(V[:,0], V[:,1])\n",
    "S=get_S(V[:,0], V[:,1])\n",
    "\n",
    "U=[*T, *S]\n",
    "U = np.array(U)\n",
    "N = int(len(U)/2)\n",
    "T=U[0:N]\n",
    "S=U[N:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The input parameter of the residual calculation is the overall solution variable. Some choice is whether the overall solution vector is organized by vertices or by blocks. We choose to operate by blocks, which is convenient to handle the residual routine from outside, but when iterating over the vertices, one should keep track on this. The return value is the vector of residuals.\n",
    "\n",
    "The boundary vertices are not handled by setting the solution value by force, but by putting the boundary assignment into the calculation of the residual. (By this definition we avoid a set-by-force handling that in turn might require extra handlings, either of the point or even their neighbors.)\n",
    "\n",
    "For example, if the boundary value at point $v_k$ is $T(v_k) = T_k$ and the boundary condition asks for $T(v_k)=0$ then the corresponding residual is set to $r(v_k) = T_k$, such that a convergence of $r(v_k) \\rightarrow 0$ gives a convergence $T(v_k) \\rightarrow 0$. \n",
    "\n",
    "Similarly, if the boundary condition asks for $T(v_k)=x_k$, as it is requiered at $y=1$, then the residual is set to $r(v_k) = T_k - x_k$, such that $r(v_k) \\rightarrow 0$ assures that$T(v_k) \\rightarrow x_k$. A pseudo-code for this case looks like this:\n",
    "\n",
    "\n",
    "            if(y_k == 1)\n",
    "                r[k] = T_k - x_k\n",
    "\n",
    "Even though the initial guess is set to the corresponding boundary value, during the iteration, that value might deviate, but it should return over the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the calculation of the gradient, we need the variable $T$ as a local parameter, the choice is to transmit the complete vector of all discrete $T$ values, that have been extracted from the overall solution vector.\n",
    "\n",
    "The gradient list is used for two purposes, (1) for the Hamiltonian of $T$, and (2) to proceed with the calculation of $S$.\n",
    "\n",
    "From the gradient list, we the calculate the norm as a step to calculate the normalized gradients (for S).\n",
    "\n",
    "The additional geometry information is needed for calculating $S$. (Though the geometry as such does not depend on the variable.) Yet, as additional ingredient $S$ specific values in terms of \n",
    "$S_{i+1/2}$, the average value in between two neighboring vertices. All this is done in a routine \"getGeometry\", where $S$ is a needed input parameter.\n",
    "\n",
    "This additional information now needs to combined with the gradients. For a better structure and clarity, the corresponding steps are outsourced in a separate subroutine, chalf = getChalf(vhalf, Thalf, gradient)\n",
    "\n",
    "Another missing component are the weights. There are several options and variants, so better keep all possibilities within an extra subroutine. The first option is to base the weights on a ponderation of $T$ or $S$ values rather than the incomingness of the gradients. The ponderation is done over the $S_{i+1/2}$ values, as these values identify the triangles.\n",
    "            \n",
    "The calculation of the residual for $S$ is done by substracting the weighted reconstructed reference value from the current approximation.\n",
    "\n",
    "So we have the two residuals calculated for each vertex.\n",
    "\n",
    "    * getGradiant: list of gradients of triangles attached to node\n",
    "    * calculate Hamiltonian of $T_k$ and thus residual for $T_k$\n",
    "    * calculate norms of gradients    \n",
    "    * normalize gradients\n",
    "    * obtain information on $n_{i+1/2}, v_{i+1/2}, S_{i+1/2}$\n",
    "    * calculate $c_{i+1/2}$ from $v_{i+1/2}$ g_{i+1/2}, S_{i+1/2}\n",
    "    * calculate ponderations $p$, based on $T_{i+1}$\n",
    "    * calculate residual for $S_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The is an issue of consistency in the length of lists, namely of the gradients on the one side and calculated values as $c$ and $p$.\n",
    "\n",
    "        chalf = getChalf(vhalf, Thalf, gradient)\n",
    "        p = getWeigts(alpha,Xlist)\n",
    "        \n",
    "The list of gradient vectors need to be adapted to handle exterior vertex neighbors, that do not have an interpretation for the calculation of the Hamiltonian, and even might fail in computation.\n",
    "So one choice is to skip the unusable components, but then there rises the problem of consistency in the length of other geometrical components.\n",
    "\n",
    "So, an alternative treatment is to mark the corresponding gradients with zero-entries and in particular the corresponding angle as a zero-angle. This avoids a failing calculation, but still generates a placeholder. This placeholder can be easily identified as such, or integrated easily without special consideration, if the weighing is set accordingly, i.e. weights propotional to the angle at least for small angles.\n",
    "\n",
    "One remaining issue is the \"nan\", either one needs to capture them, or one needs to add some smoothing factor.\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGradient(vh,T):\n",
    "    nVertex = vh.idx()\n",
    "    \n",
    "    vlist = []\n",
    "    nlist = []    \n",
    "    \n",
    "    for vvh in mesh.vv(vh):\n",
    "        idx = vvh.idx() # devuelve indice del VERTICE\n",
    "        vlist.append(idx)\n",
    "        nlist.append(V[nVertex,:]-V[idx,:])\n",
    "    nlist=np.array(nlist)\n",
    "    # print(nVertex,': \\n', nlist,'\\n')\n",
    "    \n",
    "    # for n in nlist:\n",
    "    THETA=[]\n",
    "    GRADIENT=[]\n",
    "    for k in range(len(vlist)):\n",
    "            v1 = nlist[k-1,:]\n",
    "            v2 = nlist[k,:]\n",
    "            theta = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "            I=[nVertex, vlist[k-1], vlist[k]]\n",
    "                \n",
    "            if (abs(theta) < math.pi-1e-3) and (abs(theta) > 1e-3) and (abs(theta-math.pi/2) > 1e-3):                \n",
    "                g = getGradent2(I, T[I])\n",
    "            else:\n",
    "                g = np.zeros((2,1))\n",
    "                theta = 0\n",
    "\n",
    "            THETA.append(theta)\n",
    "            GRADIENT.append(g)                \n",
    "                \n",
    "    THETA=np.array(THETA)  \n",
    "    GRADIENT=np.array(GRADIENT)\n",
    "\n",
    "    return THETA, GRADIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getGeometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGeometry(vh,X):\n",
    "    nVertex = vh.idx()\n",
    "    \n",
    "    vlist = []\n",
    "    nlist = []\n",
    "    vhalf = []\n",
    "    nhalf = []\n",
    "    Xhalf = []\n",
    "    \n",
    "    for vvh in mesh.vv(vh):\n",
    "        idx = vvh.idx() # devuelve indice del VERTICE\n",
    "        vlist.append(idx)\n",
    "        nlist.append(V[nVertex,:]-V[idx,:])\n",
    "        vhalf.append((V[nVertex,:]+V[idx,:])/2)\n",
    "        Xhalf.append((X[nVertex]+X[idx])/2)\n",
    "        \n",
    "    nlist = np.array(nlist)\n",
    "    vhalf = np.array(vhalf)\n",
    "    Xhalf = np.array(Xhalf)\n",
    "    \n",
    "    for k in range(len(vlist)):\n",
    "            n1 = nlist[k-1,:]\n",
    "            n2 = nlist[k,:]\n",
    "            nhalf.append((n1+n2)/2)\n",
    "                \n",
    "    nhalf = np.array(nhalf)\n",
    "\n",
    "    return vlist, vhalf, nhalf, Xhalf\n",
    "\n",
    "vlist, vhalf, nhalf, Shalf = getGeometry(vh,S)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getChalf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChalf(vhalf, Thalf, gradient):\n",
    "    chalf=[]\n",
    "    # for k in range(len(vhalf)):\n",
    "    for k in range(len(gradient)):   \n",
    "        g = gradient[k]\n",
    "        # avoid \"nan\"\n",
    "        g = g/(np.linalg.norm(g)+1e-5)\n",
    "        c = Thalf[k] - np.dot(g.transpose(), vhalf[k,0:2])\n",
    "        chalf.append(c)\n",
    "    \n",
    "    chalf = np.array(chalf)\n",
    "    \n",
    "    return chalf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: [ 39.75  49.5  160.5  243.5   43.5 ] -> [0.35 0.32 0.   0.   0.34]\n"
     ]
    }
   ],
   "source": [
    "# calculate weights\n",
    "def getWeigts(alpha,Xlist):\n",
    "# might run over any list\n",
    "    Xsort = np.sort(Xlist)\n",
    "    Xmean = (1-alpha)*Xsort[-1] + alpha*Xsort[1]\n",
    "    Xplus = np.maximum(Xmean - Xlist, 0)\n",
    "    # avoid \"nan\"\n",
    "    if sum(Xplus) < 1e-5:\n",
    "        print('nan [weights] !!!')\n",
    "        Xplus = Xplus + 1\n",
    "        \n",
    "    p = Xplus/sum(Xplus+1e-5)    \n",
    "\n",
    "    return p\n",
    "\n",
    "# ... need to be revised ... \n",
    "def getWeightsG(vh):\n",
    "    ng=[]\n",
    "    theta, gradient = get_theta_gradient(vh)\n",
    "    for k in range(len(nhalf)):\n",
    "        ng.append(np.dot(gradient[k].transpose(), nhalf[k,0:2]))\n",
    "\n",
    "    ng=np.array(ng).transpose()\n",
    "    return\n",
    "\n",
    "\n",
    "p = getWeigts(0.5, Thalf)\n",
    "print('p:', Thalf,'->',p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally we can iterate over the vertices:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "[  0.     0.     5.     0.     2.5    0.     0.     0.     0.    -0.\n",
      "  10.   -23.13   5.    12.61  19.39  25.7 ]\n",
      "------------------------------------------\n",
      "16 16\n"
     ]
    }
   ],
   "source": [
    "ymax=np.max(V[k,1])\n",
    "# ymax=1\n",
    "nVertex=[]\n",
    "\n",
    "def residual(U):\n",
    "    N = int(len(U)/2)\n",
    "    T=U[0:N]\n",
    "    S=U[N:]    \n",
    "    r = np.zeros(np.shape(U))\n",
    "    for vh in mesh.vertices():\n",
    "        k = vh.idx()\n",
    "        # nVertex = k\n",
    "        # print('nVertex: ', k)\n",
    "            \n",
    "        if V[k,0] == 0: # x==0\n",
    "            r[k]=U[k]     # T(x=0,y) = 0\n",
    "            r[k+N]=U[k+N] # S(x=0,y) = 0\n",
    "            # print('x=0', k)\n",
    "        elif V[k,1] == ymax: # y==0\n",
    "            r[k]=U[k]-V[k,0] # T(x,y=1) = x\n",
    "            r[k+N]=U[k+N]    # T(x,y=1) = 0\n",
    "            # print('y=ymax', k)\n",
    "        else: # interior\n",
    "            # list of gradients\n",
    "            theta, gradient = getGradient(vh,T)\n",
    "\n",
    "            # calculate gradient for Hamiltonian of T_k\n",
    "            # calculate residual for equation T_k            \n",
    "            gav = gradient.transpose().dot(theta)/sum(theta)\n",
    "            r[nVertex] = np.linalg.norm(gav) - V[nVertex,1]/(U[N+k] + 1e-5)\n",
    "                    \n",
    "            # normalize gradients, corrsponding to $\\nabla S$\n",
    "            ahalf = gradient[:,0]\n",
    "            bhalf = gradient[:,1]\n",
    "            gnorm = (ahalf**2 + bhalf**2)**(0.5)     \n",
    "            ahalf=ahalf/(gnorm+1e-5)\n",
    "            bhalf=bhalf/(gnorm+1e-5)\n",
    "            \n",
    "            # get additional geometry information for $S$\n",
    "            vlist, vhalf, nhalf, Shalf = getGeometry(vh,S)\n",
    "                     \n",
    "            # calculate $c$ values\n",
    "            chalf = getChalf(vhalf, Shalf, gradient)\n",
    "                        \n",
    "            SS=ahalf*V[k,0] + bhalf*V[k,1] + chalf\n",
    "            \n",
    "            # calculate weights\n",
    "            p = getWeigts(0.5, Shalf)\n",
    "            \n",
    "            Sbar = np.dot(p,SS)\n",
    "            r[k+N]=S[k]-Sbar\n",
    "            \n",
    "        if False:\n",
    "            print('------------------------------------------')            \n",
    "            print('a', ahalf)\n",
    "            print('b', bhalf)\n",
    "            print('v', vhalf)\n",
    "            print('Vk1', V[k,1])            \n",
    "            print('c', chalf)\n",
    "            print('g', gradient)\n",
    "            print('p', p)        \n",
    "            print('SS:', SS)\n",
    "            print('------------------------------------------')\n",
    "            \n",
    "        #\n",
    "        #\n",
    "        # print('k =', k, ', \\t r :', r)\n",
    "        # \n",
    "    return r\n",
    "\n",
    "def cost(u):\n",
    "    R=residual(u)\n",
    "    c=np.inner(R,R)\n",
    "    return c\n",
    "\n",
    "print('------------------------------------------')\n",
    "res = residual(U)\n",
    "print(res)\n",
    "print('------------------------------------------')\n",
    "print(len(res), len(U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the definition of the residual, that generates as many equations as variables, two equations and variables for each vertex, we can proceed in solving this system of equations. Though an explicite handling might have been a choice, an implicit handling in form of solving a system of non-linear equations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown parameter options",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-12336256e2d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# res =  fsolve(residual, U)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# res = newton_krylov(residual, U, method='lgmres', verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewton_krylov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lgmres'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'maxiter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'disp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print('Residual: %g' % abs(residual(res)).max())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/nonlin.py\u001b[0m in \u001b[0;36mnewton_krylov\u001b[0;34m(F, xin, iter, rdiff, method, inner_maxiter, inner_M, outer_k, verbose, maxiter, f_tol, f_rtol, x_tol, x_rtol, tol_norm, line_search, callback, **kw)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/nonlin.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rdiff, method, inner_maxiter, inner_M, outer_k, **kw)\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inner_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown parameter %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown parameter options"
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "from scipy.optimize import fsolve, newton_krylov\n",
    "\n",
    "# res = optimize.broyden1(residual, U)\n",
    "# res =  fsolve(residual, U)\n",
    "# res = newton_krylov(residual, U, method='lgmres', verbose=1)\n",
    "res = newton_krylov(residual, U, method='lgmres', verbose=1)\n",
    "\n",
    "# print('Residual: %g' % abs(residual(res)).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "for method in ('nelder-mead', 'powell', 'cobyla','L-BFGS-B','BFGS'):\n",
    "    t0 = time.time()\n",
    "    res = opt.minimize(cost, U, method=method, tol=1e-10, options={'maxiter': 2, 'disp': True})\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # U = res.x\n",
    "    print(res)\n",
    "    print('\\n<<< ---------',k,'----  %s' % method, ' ------ dt = %.1f \\n\\n\\n' % float(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
